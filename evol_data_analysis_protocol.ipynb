{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from random import random\n",
    "from subst_mat_lib_2 import *\n",
    "from rand_arr_generate import *\n",
    "from math import log10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Loading substitution matrices</b>\n",
    "<p> Substitution matrices were obtained with the substitution_matrix_r4.py script</p>\n",
    "<p> Using the subst_mat_read function from the subst_mat_lib library</p>\n",
    "<p> Loading separately: <br>\n",
    "    1. Matrices for synonimous sites <br>\n",
    "    2. Matrices for nonsynonimous sites <br>\n",
    "    3. Matrices for both synonimous and nonsynonimous sites\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smat_bim_all = subst_mat_read(\"smat_bim.txt\")[1]\n",
    "smat_oct_all = subst_mat_read(\"smat_oct.txt\")[1]\n",
    "smat_sep_all = subst_mat_read(\"smat_sep.txt\")[1]\n",
    "smat_squ_all = subst_mat_read(\"smat_squ.txt\")[1]\n",
    "\n",
    "smat_bim_syn = subst_mat_read(\"smat_bim_syn.txt\")[1]\n",
    "smat_oct_syn = subst_mat_read(\"smat_oct_syn.txt\")[1]\n",
    "smat_sep_syn = subst_mat_read(\"smat_sep_syn.txt\")[1]\n",
    "smat_squ_syn = subst_mat_read(\"smat_squ_syn.txt\")[1]\n",
    "\n",
    "smat_bim_nsyn = subst_mat_read(\"smat_bim_nsyn.txt\")[1]\n",
    "smat_oct_nsyn = subst_mat_read(\"smat_oct_nsyn.txt\")[1]\n",
    "smat_sep_nsyn = subst_mat_read(\"smat_sep_nsyn.txt\")[1]\n",
    "smat_squ_nsyn = subst_mat_read(\"smat_squ_nsyn.txt\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Calculating sums of matrices for closely related species</b>\n",
    "<p>Using the sum_subst_mats function from the subst_mat_lib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smat_squ_sep_all = sum_subst_mats(smat_squ_all, smat_sep_all)\n",
    "smat_bim_oct_all = sum_subst_mats(smat_bim_all, smat_oct_all)\n",
    "\n",
    "smat_bim_oct_syn = sum_subst_mats(smat_bim_syn, smat_oct_syn)\n",
    "smat_squ_sep_syn = sum_subst_mats(smat_squ_syn, smat_sep_syn)\n",
    "\n",
    "smat_bim_oct_nsyn = sum_subst_mats(smat_bim_nsyn, smat_oct_nsyn)\n",
    "smat_squ_sep_nsyn = sum_subst_mats(smat_squ_nsyn, smat_sep_nsyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q<sub>→*</sub> count</h3>\n",
    "\n",
    "<h4>And estimating different effects, underlying Q<sub>→*</sub></h4>\n",
    "<p>Q<sub>→*</sub> harbours two effects: <br>\n",
    "1. Change of the E → G mutation frequency (relative to A → G)<br>\n",
    "2. Change of the E → Y mutation frequency (relative to A → Y)<br>\n",
    "Thus, we consider four mutatioal probabilities:\n",
    "E → G, E → Y, A → G, A → Y</p>\n",
    "<p>When counting R and Q for synonimous and non-synonimous sites separately,\n",
    "we employ coefficients reflecting differences in synonimous and non-synonimous\n",
    "mutation rates</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_and_Q_E2G_count(smat, precision, alpha_arr, coeff_G, coeff_Y):\n",
    "    let_arr = ['A','E','G','C','T']\n",
    "    sum_E = colsum(smat, 'E')\n",
    "    p_E2G = float(smat['E']['G'])/sum_E\n",
    "    p_E2Y = float(smat['E']['C'] + smat['E']['T'])/sum_E\n",
    "    sum_A = colsum(smat, 'A')\n",
    "    p_A2G = float(smat['A']['G'])/sum_A\n",
    "    p_A2Y = float(smat['A']['C'] + smat['A']['T'])/sum_A\n",
    "    \n",
    "    mean_rg = p_E2G*coeff_G/p_A2G\n",
    "    mean_ry = p_E2Y*coeff_Y/p_A2Y\n",
    "    mean_q = mean_rg/mean_ry\n",
    "#    print(mean_rg)\n",
    "#    print(mean_ry)\n",
    "#    print(mean_q)\n",
    "#    \n",
    "    E2G = rand_arr_generate(precision, sum_E, p_E2G)\n",
    "    E2Y = rand_arr_generate(precision, sum_E, p_E2Y)\n",
    "    A2G = rand_arr_generate(precision, sum_A, p_A2G)\n",
    "    A2Y = rand_arr_generate(precision, sum_A, p_A2Y)\n",
    "    \n",
    "    for i in range(precision):\n",
    "        if E2Y[i] == 0:\n",
    "            E2Y[i] = 0.001\n",
    "        if A2G[i] == 0:\n",
    "            A2G[i] = 0.001\n",
    "        if A2Y[i] == 0:\n",
    "            A2Y[i] = 0.001\n",
    "    \n",
    "    rg_vals = [E2G[i]*coeff_G*sum_A/(A2G[i]*sum_E) for i in range(precision)]\n",
    "    ry_vals = [E2Y[i]*coeff_Y*sum_A/(A2Y[i]*sum_E) for i in range(precision)]\n",
    "    q_vals = [rg_vals[i]/ry_vals[i] for i in range(precision)]\n",
    "    rg_vals = sorted(rg_vals)\n",
    "    ry_vals = sorted(ry_vals)\n",
    "    q_vals = sorted(q_vals)\n",
    "    \n",
    "    alpha_dict_rg = dict()\n",
    "    alpha_dict_ry = dict()\n",
    "    alpha_dict_q = dict()\n",
    "    for alpha in alpha_arr:\n",
    "        alpha_dict_q[alpha] = dict()\n",
    "        alpha_dict_q[alpha][\"min\"] = q_vals[int(precision*(alpha/2))]\n",
    "        alpha_dict_q[alpha][\"max\"] = q_vals[-int(precision*(alpha/2))]\n",
    "        alpha_dict_rg[alpha] = dict()\n",
    "        alpha_dict_rg[alpha][\"min\"] = rg_vals[int(precision*(alpha/2))]\n",
    "        alpha_dict_rg[alpha][\"max\"] = rg_vals[-int(precision*(alpha/2))]\n",
    "        alpha_dict_ry[alpha] = dict()\n",
    "        alpha_dict_ry[alpha][\"min\"] = ry_vals[int(precision*(alpha/2))]\n",
    "        alpha_dict_ry[alpha][\"max\"] = ry_vals[-int(precision*(alpha/2))]\n",
    "        \n",
    "    return mean_q, mean_rg, mean_ry, alpha_dict_rg, alpha_dict_ry, alpha_dict_q\n",
    "\n",
    "def alpha_dict_print(alpha_dict):\n",
    "    res_arr = []\n",
    "    for alpha in sorted(alpha_dict.keys())[::-1]:\n",
    "        res_arr.append(alpha_dict[alpha][\"min\"])\n",
    "        res_arr.append(alpha_dict[alpha][\"max\"])\n",
    "    return res_arr\n",
    "\n",
    "def print_for_smat(smat, precision, alpha_arr, species, outfile, coeff_G, coeff_Y):\n",
    "    mean_q, mean_rg, mean_ry, alpha_dict_rg, alpha_dict_ry, alpha_dict_q = R_and_Q_E2G_count(smat, precision, alpha_arr, coeff_G, coeff_Y)\n",
    "    alpha_arr_rg = alpha_dict_print(alpha_dict_rg)\n",
    "    alpha_arr_ry = alpha_dict_print(alpha_dict_ry)\n",
    "    alpha_arr_q = alpha_dict_print(alpha_dict_q)\n",
    "    outfile.write('Q' + species + '\\t' + str(mean_q)+'\\t'+'\\t'.join(map(str,alpha_arr_q))  + '\\n')\n",
    "    outfile.write('RG' + species + '\\t' + str(mean_rg)+'\\t'+'\\t'.join(map(str,alpha_arr_rg)) + '\\n')\n",
    "    outfile.write('RY' + species + '\\t' + str(mean_ry)+'\\t'+'\\t'.join(map(str,alpha_arr_ry)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coeffs: substitution_matrix_6_1.py output\n",
    "#subst_mat_print(smat_squ_sep_all)\n",
    "coeff_G_all = 1.0\n",
    "coeff_Y_all = 1.0\n",
    "coeff_G_syn = 0.0198403586868/0.0839480367971\n",
    "coeff_Y_syn = 0.0103003952764/0.0342816172271\n",
    "coeff_G_nsyn = 0.0198403586868/0.00349503011675\n",
    "coeff_Y_nsyn = 0.0103003952764/0.00418598021962\n",
    "\n",
    "outfile_sep_squ_all = open(\"rs_and_qs/sep_squ_all_1.txt\", 'w')\n",
    "outfile_sep_squ_nsyn = open(\"rs_and_qs/sep_squ_nsyn_1.txt\", 'w')\n",
    "outfile_sep_squ_syn = open(\"rs_and_qs/sep_squ_syn_1.txt\", 'w')\n",
    "\n",
    "print_for_smat(smat_squ_sep_all,  100000, [0.1, 0.05, 0.01], \"Q2*\", outfile_sep_squ_all , coeff_G_all , coeff_Y_all )\n",
    "print_for_smat(smat_squ_sep_nsyn, 100000, [0.1, 0.05, 0.01], \"Q2*\", outfile_sep_squ_nsyn, coeff_G_nsyn, coeff_Y_nsyn)\n",
    "print_for_smat(smat_squ_sep_syn,  100000, [0.1, 0.05, 0.01], \"Q2*\", outfile_sep_squ_syn , coeff_G_syn , coeff_Y_syn )\n",
    "\n",
    "#print_for_smat(smat_squ_sep_all,  100000, [0.1, 0.05, 0.01], \"Q2*\", sys.stdout, coeff_G_all, coeff_Y_all)\n",
    "#print_for_smat(smat_squ_sep_nsyn, 100000, [0.1, 0.05, 0.01], \"Q2*\", sys.stdout, coeff_G_nsyn, coeff_Y_nsyn)\n",
    "#print_for_smat(smat_squ_sep_syn,  100000, [0.1, 0.05, 0.01], \"Q2*\", sys.stdout, coeff_G_syn, coeff_Y_syn)\n",
    "\n",
    "outfile_sep_squ_all.close()\n",
    "outfile_sep_squ_nsyn.close()\n",
    "outfile_sep_squ_syn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q<sub>*→</sub> count</h3>\n",
    "\n",
    "<h4>Estimating different effects, underlying Q<sub>*→</sub></h4>\n",
    "<p>This Q harbours two effects: <br>\n",
    "1. Change of the G → E mutation frequency (relative to G → A)<br>\n",
    "2. Change of the Y → E mutation frequency (relative to Y → A)<br>\n",
    "Thus, we consider four mutatioal probabilities:\n",
    "G → E, Y → E, G → A, Y → A</p>\n",
    "<p>But we consider conditional probabilities, that take into account drastic differences beween numbers of E and A sites</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_and_Q_G2E_count(smat, precision, alpha_arr, cond_prob_E, cond_prob_A, coeff_G, coeff_Y):\n",
    "    sum_G = colsum(smat, 'G')\n",
    "    p_G2E = float(smat['G']['E'])/sum_G\n",
    "    p_G2A = float(smat['G']['A'])/sum_G\n",
    "    sum_Y = colsum(smat, 'C') + colsum(smat, 'T')\n",
    "    p_Y2E = float(smat['C']['E'] + smat['T']['E'])/sum_Y\n",
    "    p_Y2A = float(smat['C']['A'] + smat['T']['A'])/sum_Y\n",
    "    \n",
    "    mean_rg = p_G2E*cond_prob_A*coeff_G/(p_G2A*cond_prob_E)\n",
    "    mean_ry = p_Y2E*cond_prob_A*coeff_Y/(p_Y2A*cond_prob_E)\n",
    "    mean_q = mean_rg/mean_ry\n",
    "    \n",
    "    G2E = rand_arr_generate(precision, sum_G, p_G2E)\n",
    "    Y2E = rand_arr_generate(precision, sum_Y, p_Y2E)\n",
    "    G2A = rand_arr_generate(precision, sum_G, p_G2A)\n",
    "    Y2A = rand_arr_generate(precision, sum_Y, p_Y2A)\n",
    "    \n",
    "    for i in range(precision):\n",
    "        if Y2E[i] == 0:\n",
    "            Y2E[i] = 0.001\n",
    "        if G2A[i] == 0:\n",
    "            G2A[i] = 0.001\n",
    "        if Y2A[i] == 0:\n",
    "            Y2A[i] = 0.001\n",
    "\n",
    "    rg_vals = [G2E[i]*cond_prob_A*coeff_G/(G2A[i]*cond_prob_E) for i in range(precision)]\n",
    "    ry_vals = [Y2E[i]*cond_prob_A*coeff_Y/(Y2A[i]*cond_prob_E) for i in range(precision)]\n",
    "    q_vals = [rg_vals[i]/ry_vals[i] for i in range(precision)]\n",
    "    rg_vals = sorted(rg_vals)\n",
    "    ry_vals = sorted(ry_vals)\n",
    "    q_vals = sorted(q_vals)\n",
    "    \n",
    "    alpha_dict_rg = dict()\n",
    "    alpha_dict_ry = dict()\n",
    "    alpha_dict_q = dict()\n",
    "    for alpha in alpha_arr:\n",
    "        alpha_dict_q[alpha] = dict()\n",
    "        alpha_dict_q[alpha][\"min\"] = q_vals[int(precision*(alpha/2))]\n",
    "        alpha_dict_q[alpha][\"max\"] = q_vals[-int(precision*(alpha/2))]\n",
    "        alpha_dict_rg[alpha] = dict()\n",
    "        alpha_dict_rg[alpha][\"min\"] = rg_vals[int(precision*(alpha/2))]\n",
    "        alpha_dict_rg[alpha][\"max\"] = rg_vals[-int(precision*(alpha/2))]\n",
    "        alpha_dict_ry[alpha] = dict()\n",
    "        alpha_dict_ry[alpha][\"min\"] = ry_vals[int(precision*(alpha/2))]\n",
    "        alpha_dict_ry[alpha][\"max\"] = ry_vals[-int(precision*(alpha/2))]\n",
    "        \n",
    "    return mean_q, mean_rg, mean_ry, alpha_dict_rg, alpha_dict_ry, alpha_dict_q\n",
    "\n",
    "def print_for_smat_2(smat, precision, alpha_arr, cond_prob_E, cond_prob_A, coeff_G, coeff_Y, species, outfile):\n",
    "    mean_q, mean_rg, mean_ry, alpha_dict_rg, alpha_dict_ry, alpha_dict_q = R_and_Q_G2E_count(smat, precision, alpha_arr, cond_prob_E, cond_prob_A, coeff_G, coeff_Y)\n",
    "    alpha_arr_rg = alpha_dict_print(alpha_dict_rg)\n",
    "    alpha_arr_ry = alpha_dict_print(alpha_dict_ry)\n",
    "    alpha_arr_q = alpha_dict_print(alpha_dict_q)\n",
    "    outfile.write('Q' + species + '\\t' + str(mean_q)+'\\t'+'\\t'.join(map(str,alpha_arr_q))  + '\\n')\n",
    "    outfile.write('RG' + species + '\\t' + str(mean_rg)+'\\t'+'\\t'.join(map(str,alpha_arr_rg)) + '\\n')\n",
    "    outfile.write('RY' + species + '\\t' + str(mean_ry)+'\\t'+'\\t'.join(map(str,alpha_arr_ry)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "nf_E_all = float(126868 + 76886 + 3768 + 6089)/(7769122 + 6831947)\n",
    "nf_A_all = 1 - nf_E_all\n",
    "\n",
    "nf_E_syn = float(28688 + 44406)/(7769122 + 6831947)\n",
    "nf_A_syn = 1 - nf_E_syn\n",
    "\n",
    "nf_E_nsyn = nf_E_all - nf_E_syn\n",
    "nf_A_nsyn = 1 - nf_E_nsyn\n",
    "\n",
    "nf_E_all_oct = float(75316 + 39634 + 17414 + 5281 + 114624 + 44472 + 16751 + 3733)/(10043547 + 7749608)\n",
    "nf_A_all_oct = 1 - nf_E_all_oct\n",
    "\n",
    "nf_E_syn_oct = float(26783 + 41203)/(10043547 + 7749608)\n",
    "nf_A_syn_oct = 1 - nf_E_syn_oct\n",
    "\n",
    "nf_E_nsyn_oct = nf_E_all_oct - nf_E_syn_oct\n",
    "nf_A_nsyn_oct = 1 - nf_E_nsyn_oct\n",
    "\n",
    "coeff_G_all = 1.0\n",
    "coeff_Y_all = 1.0\n",
    "coeff_G_syn = 0.0198403586868/0.0839480367971\n",
    "coeff_Y_syn = 0.0103003952764/0.0342816172271\n",
    "coeff_G_nsyn = 0.0198403586868/0.00349503011675\n",
    "coeff_Y_nsyn = 0.0103003952764/0.00418598021962\n",
    "\n",
    "coeff_G_oct_all = 1.0\n",
    "coeff_Y_oct_all = 1.0\n",
    "coeff_G_oct_syn = 0.00296624439781/0.0172659591319\n",
    "coeff_Y_oct_syn = 0.000798302147627/0.00185663133626\n",
    "coeff_G_oct_nsyn = 0.00296624439781/0.0011175505165\n",
    "coeff_Y_oct_nsyn = 0.000798302147627/0.000437030214284\n",
    "\n",
    "outfile_sep_squ_all  = open(\"rs_and_qs/sep_squ_all_1.txt\", 'a')\n",
    "outfile_sep_squ_nsyn = open(\"rs_and_qs/sep_squ_nsyn_1.txt\", 'a')\n",
    "outfile_sep_squ_syn  = open(\"rs_and_qs/sep_squ_syn_1.txt\", 'a')\n",
    "outfile_bim_oct_all  = open(\"rs_and_qs/bim_oct_all_1.txt\", 'w')\n",
    "outfile_bim_oct_nsyn = open(\"rs_and_qs/bim_oct_nsyn_1.txt\", 'w')\n",
    "outfile_bim_oct_syn  = open(\"rs_and_qs/bim_oct_syn_1.txt\", 'w')\n",
    "\n",
    "#print_for_smat_2(smat_squ_sep_all,  100000, [0.1, 0.05, 0.01], nf_E_all, nf_A_all, coeff_G_all, coeff_Y_all, \"Q*2\", sys.stdout)\n",
    "#print_for_smat_2(smat_squ_sep_nsyn, 100000, [0.1, 0.05, 0.01], nf_E_nsyn, nf_A_nsyn, coeff_G_nsyn, coeff_Y_nsyn, \"Q*2\", sys.stdout)\n",
    "#print_for_smat_2(smat_squ_sep_syn,  100000, [0.1, 0.05, 0.01], nf_E_syn, nf_A_syn, coeff_G_syn, coeff_Y_syn, \"Q*2\", sys.stdout)\n",
    "#\n",
    "#print_for_smat_2(smat_bim_oct_all,  100000, [0.1, 0.05, 0.01], nf_E_all_oct, nf_A_all_oct, coeff_G_oct_all, coeff_Y_all, \"Q*2\", sys.stdout)\n",
    "#print_for_smat_2(smat_bim_oct_nsyn, 100000, [0.1, 0.05, 0.01], nf_E_nsyn_oct, nf_A_nsyn_oct, coeff_G_oct_nsyn, coeff_Y_nsyn, \"Q*2\", sys.stdout)\n",
    "#print_for_smat_2(smat_bim_oct_syn,  100000, [0.1, 0.05, 0.01], nf_E_syn_oct, nf_A_syn_oct, coeff_G_oct_syn, coeff_Y_syn, \"Q*2\", sys.stdout)\n",
    "\n",
    "print_for_smat_2(smat_squ_sep_all,  100000, [0.1, 0.05, 0.01], nf_E_all, nf_A_all, coeff_G_all, coeff_Y_all, \"Q*2\", outfile_sep_squ_all)\n",
    "print_for_smat_2(smat_squ_sep_nsyn, 100000, [0.1, 0.05, 0.01], nf_E_nsyn, nf_A_nsyn, coeff_G_nsyn, coeff_Y_nsyn, \"Q*2\", outfile_sep_squ_nsyn)\n",
    "print_for_smat_2(smat_squ_sep_syn,  100000, [0.1, 0.05, 0.01], nf_E_syn, nf_A_syn, coeff_G_syn, coeff_Y_syn, \"Q*2\", outfile_sep_squ_syn)\n",
    "\n",
    "print_for_smat_2(smat_bim_oct_all,  100000, [0.1, 0.05, 0.01], nf_E_all_oct, nf_A_all_oct, coeff_G_oct_all, coeff_Y_all, \"Q*2\", outfile_bim_oct_all)\n",
    "print_for_smat_2(smat_bim_oct_nsyn, 100000, [0.1, 0.05, 0.01], nf_E_nsyn_oct, nf_A_nsyn_oct, coeff_G_oct_nsyn, coeff_Y_nsyn, \"Q*2\", outfile_bim_oct_nsyn)\n",
    "print_for_smat_2(smat_bim_oct_syn,  100000, [0.1, 0.05, 0.01], nf_E_syn_oct, nf_A_syn_oct, coeff_G_oct_syn, coeff_Y_syn, \"Q*2\", outfile_bim_oct_syn)\n",
    "\n",
    "outfile_sep_squ_all.close()\n",
    "outfile_sep_squ_nsyn.close()\n",
    "outfile_sep_squ_syn.close()\n",
    "outfile_bim_oct_all.close()\n",
    "outfile_bim_oct_nsyn.close()\n",
    "outfile_bim_oct_syn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Editing events parallel evolution</h3>\n",
    "<p>Data is obtained with the parallel_count_2.py script separately for synonimous, non-synonimous and all sites</p>\n",
    "<p>Confidence intervals are obtained from binomial distribution</p>\n",
    "<p>Parallel events A → G are considered as a control</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confints_paral(n_muts, n_sites, ref_p_1, ref_p_2, alpha_arr, annotation, outfile):\n",
    "    res_arr = [annotation]\n",
    "    ref_p = float(n_muts)/n_sites\n",
    "    res_arr.append(ref_p/(ref_p_1*ref_p_2))\n",
    "    for alpha in alpha_arr:\n",
    "        a = st.binom.interval(alpha, n_sites, ref_p, loc=0)\n",
    "        res_arr.append((float(a[0])/n_sites)/(ref_p_1*ref_p_2))\n",
    "        res_arr.append((float(a[1])/n_sites)/(ref_p_1*ref_p_2))\n",
    "    outfile.write('\\t'.join(map(str, res_arr)) + '\\n')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_muts_all = 83\n",
    "n_muts_syn = 21\n",
    "n_muts_nsyn = 61\n",
    "\n",
    "n_muts_G = 16\n",
    "n_muts_G_syn = 14\n",
    "n_muts_G_nsyn = 2\n",
    "syn_G_frac = 0.34\n",
    "n_sites = 35494\n",
    "\n",
    "\n",
    "outfile_main = open(\"sep_squ_fig4.txt\", 'a')\n",
    "outfile_nes = open(\"sep_squ_nes.txt\", 'a')\n",
    "outfile_ses = open(\"sep_squ_ses.txt\", 'a')\n",
    "\n",
    "#All\n",
    "ref_p_1 = max(smat_squ['A']['E']/colsum(smat_squ, 'A'), smat_sep['A']['E']/colsum(smat_sep, 'A'))\n",
    "ref_p_2 = max(smat_oct['A']['E']/colsum(smat_oct, 'A'), smat_bim['A']['E']/colsum(smat_bim, 'A'))\n",
    "\n",
    "confints_paral(n_muts_all, n_sites, ref_p_1, ref_p_2, [0.9,0.95,0.99], \"All_sites_E\", outfile_main)\n",
    "\n",
    "#syn\n",
    "ref_p_1 = max(smat_squ_syn['A']['E']/colsum(smat_squ_syn, 'A'), smat_sep_syn['A']['E']/colsum(smat_sep_syn, 'A'))\n",
    "ref_p_2 = max(smat_oct_syn['A']['E']/colsum(smat_oct_syn, 'A'), smat_bim_syn['A']['E']/colsum(smat_bim_syn, 'A'))\n",
    "\n",
    "confints_paral(n_muts_G, n_sites, ref_p_1, ref_p_2, [0.9,0.95,0.99], \"syn\", outfile_ses)\n",
    "\n",
    "#nsyn\n",
    "ref_p_1 = max(smat_squ_nsyn['A']['E']/colsum(smat_squ_nsyn, 'A'), smat_sep_nsyn['A']['E']/colsum(smat_sep_nsyn, 'A'))\n",
    "ref_p_2 = max(smat_oct_nsyn['A']['E']/colsum(smat_oct_nsyn, 'A'), smat_bim_nsyn['A']['E']/colsum(smat_bim_nsyn, 'A'))\n",
    "\n",
    "confints_paral(n_muts_G, n_sites, ref_p_1, ref_p_2, [0.9,0.95,0.99], \"nsyn\", outfile_nes)\n",
    "\n",
    "#G_all\n",
    "ref_p_1 = max(smat_squ['A']['G']/colsum(smat_squ, 'A'), smat_sep['A']['G']/colsum(smat_sep, 'A'))\n",
    "ref_p_2 = max(smat_oct['A']['G']/colsum(smat_oct, 'A'), smat_bim['A']['G']/colsum(smat_bim, 'A'))\n",
    "\n",
    "confints_paral(n_muts_G, n_sites, ref_p_1, ref_p_2, [0.9,0.95,0.99], \"G\", outfile_main)\n",
    "\n",
    "#G_syn\n",
    "confints_paral(n_muts_G_syn, int(n_sites*syn_G_frac), ref_p_1, ref_p_2, [0.9,0.95,0.99], \"G\", outfile_ses)\n",
    "\n",
    "#G_nsyn\n",
    "confints_paral(n_muts_G_nsyn, int(n_sites*(1-syn_G_frac)), ref_p_1, ref_p_2, [0.9,0.95,0.99], \"G\", outfile_nes)\n",
    "\n",
    "outfile_main.close()\n",
    "outfile_nes.close()\n",
    "outfile_ses.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evolution modelling using substitution matrices</h3>\n",
    "<p>Normalized substitution matrix is multiplied multiple times with the vector with nucleotide numbers</p>\n",
    "<p>Along with that, two sets of values are calculated:<br>\n",
    "1. Numbers of E nucleotides that emerge from each nucleotide (toE)<br>\n",
    "2. Numbers of nucleotides that emerge from E nucleotides (fromE)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evol(smat_n, nucl_arr, n_range, outfile_name, outf_fromE_name, outf_toE_name):\n",
    "#    let_arr = ['A','G','C','T']\n",
    "    let_arr = ['A','E','G','C','T']\n",
    "    a = np.array([[smat_n[l1][l2] for l2 in let_arr] for l1 in let_arr])\n",
    "    b = np.array(nucl_arr)\n",
    "    with open(outfile_name, \"w\") as outfile_evol, open(outf_fromE_name, 'w') as outf_fromE, open(outf_toE_name, 'w') as outf_toE:\n",
    "        \n",
    "        outfile_evol.write('\\t'.join(let_arr) + '\\n')\n",
    "        outfile_evol.write('\\t'.join(map(str, b)) + '\\n')\n",
    "        \n",
    "        outf_fromE.write('\\t'.join(let_arr) + '\\n')\n",
    "        outf_toE.write('\\t'.join(let_arr) + '\\n')\n",
    "        for i in range(n_range):\n",
    "            b1 = np.matmul(b, a)\n",
    "            outfile_evol.write('\\t'.join(map(str,b1)) + '\\t' + str(sum(b1)) + '\\n')\n",
    "            \n",
    "            fromE_arr = []\n",
    "            toE_arr = []\n",
    "            for i in range(5):\n",
    "                fromE_arr.append(b[1]*smat_n['E'][let_arr[i]])\n",
    "                toE_arr.append(b[i]*smat_n[let_arr[i]]['E'])\n",
    "                \n",
    "            outf_fromE.write('\\t'.join(map(str,fromE_arr)) + '\\n')\n",
    "            outf_toE.write('\\t'.join(map(str, toE_arr)) + '\\n')\n",
    "            b = b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucl_arr_bim = [9968231, 76862, 6211485, 6099841, 9087468]\n",
    "nucl_arr_oct = [7634984, 117842, 4770934, 4729830, 6999038]\n",
    "nucl_arr_sep = [7642254, 130636, 4896006, 4811269, 6990703]\n",
    "nucl_arr_squ = [6755061, 82975, 4347879, 4280405, 5994621]\n",
    "nucl_arr_sep_squ = [nucl_arr_sep[i] + nucl_arr_squ[i] for i in range(5)]\n",
    "nucl_arr_bim_oct = [nucl_arr_bim[i] + nucl_arr_oct[i] for i in range(5)]\n",
    "\n",
    "nucl_arr_sep_squ_syn = [14537832, 73094, 9243885, 9091674, 12985324]\n",
    "nucl_arr_sep_squ_nsyn = [14470409, 140517, 9243885, 9091674, 12985324]\n",
    "\n",
    "bim_n = subst_mat_normalize(smat_bim)\n",
    "oct_n = subst_mat_normalize(smat_oct)\n",
    "sep_n = subst_mat_normalize(smat_sep)\n",
    "squ_n = subst_mat_normalize(smat_squ)\n",
    "squ_sep_n = subst_mat_normalize(smat_squ_sep)\n",
    "bim_oct_n = subst_mat_normalize(smat_bim_oct)\n",
    "squ_sep_syn_n = subst_mat_normalize(smat_squ_sep_syn)\n",
    "squ_sep_nsyn_n = subst_mat_normalize(smat_squ_sep_nsyn)\n",
    "\n",
    "\n",
    "print_evol(squ_sep_syn_n, nucl_arr_sep_squ_syn, 50, \"squ_sep_evol_syn.txt\", \"squ_sep_fromE_syn.txt\", \"squ_sep_toE_syn.txt\")\n",
    "print_evol(squ_sep_nsyn_n, nucl_arr_sep_squ_nsyn, 50, \"squ_sep_evol_nsyn.txt\", \"squ_sep_fromE_nsyn.txt\", \"squ_sep_toE_nsyn.txt\")\n",
    "\n",
    "print_evol(bim_oct_n, nucl_arr_bim_oct, 500, \"bim_oct_evol.txt\", \"bim_oct_fromE.txt\", \"bim_oct_toE.txt\")\n",
    "#print_evol(bim_n, nucl_arr_bim, 500, \"bim_evol.txt\", \"bim_fromE.txt\", \"bim_toE.txt\")\n",
    "#print_evol(oct_n, nucl_arr_oct, 500, \"oct_evol.txt\", \"oct_fromE.txt\", \"oct_toE.txt\")\n",
    "#print_evol(sep_n, nucl_arr_sep, 50, \"sep_evol.txt\", \"sep_fromE.txt\", \"sep_toE.txt\")\n",
    "#print_evol(squ_n, nucl_arr_squ, 50, \"squ_evol.txt\", \"squ_fromE.txt\", \"squ_toE.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evol_control(smat_n, nucl_arr, n_range, outfile_name):\n",
    "    let_arr = ['A','G','C','T']\n",
    "    a = np.array([[smat_n[l1][l2] for l2 in let_arr] for l1 in let_arr])\n",
    "    b = np.array(nucl_arr)\n",
    "    with open(outfile_name, \"w\") as outfile:\n",
    "        outfile.write('\\t'.join(let_arr) + '\\tS' + '\\n')\n",
    "        n = map(str, list(b))\n",
    "        outfile.write('\\t'.join(map(str, list(b))) + '\\t'+ str(sum(b)) + '\\n')\n",
    "        for i in range(n_range):\n",
    "            b1 = np.matmul(b, a)\n",
    "            outfile.write('\\t'.join(map(str,b1)) + '\\t' + str(sum(b1)) + '\\n')\n",
    "            b = b1\n",
    "\n",
    "def colsum2(smat, let):\n",
    "#    print(smat)\n",
    "    let_arr = ['A','G','C','T']\n",
    "    _sum = 0\n",
    "    for c in let_arr:\n",
    "        _sum += smat[let][c]\n",
    "    return _sum\n",
    "\n",
    "def print_control(nucl_arr, smat, mult_num, outfile_name):\n",
    "#    print(nucl_arr)\n",
    "    new_nucl_arr = nucl_arr[:1] + nucl_arr[2:]\n",
    "    smat_c = dict()\n",
    "    for i in ['A','G','C','T']:\n",
    "        smat_c[i] = dict()\n",
    "        for j in ['A','G','C','T']:\n",
    "            smat_c[i][j] = smat[i][j]\n",
    "    n = dict()\n",
    "    for k1 in smat_c.keys():\n",
    "        n[k1] = dict()\n",
    "        for k2 in smat_c[k1].keys():\n",
    "            n[k1][k2] = float(smat_c[k1][k2])/colsum2(smat_c, k1)\n",
    "    print_evol_control(n, new_nucl_arr, mult_num, outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14397315, 213611, 9243885, 9091674, 12985324]\n"
     ]
    }
   ],
   "source": [
    "#print_control(nucl_arr_sep_squ_syn, smat_squ_sep_syn, 50, \"squ_sep_evol_syn_control.txt\")\n",
    "#print_control(nucl_arr_sep_squ_nsyn, smat_squ_sep_nsyn, 50, \"squ_sep_evol_nsyn_control.txt\")\n",
    "\n",
    "#print_control(nucl_arr_bim, smat_bim, 500, \"bim_evol_control.txt\")\n",
    "#print_control(nucl_arr_oct, smat_oct, 500, \"oct_evol_control.txt\")\n",
    "#print_control(nucl_arr_sep, smat_sep, 50, \"sep_evol_control.txt\")\n",
    "#print_control(nucl_arr_squ, smat_squ, 50, \"squ_evol_control.txt\")\n",
    "\n",
    "nucl_arr_sep_squ = [14397315, 213611, 9243885, 9091674, 12985324]\n",
    "\n",
    "print_evol(squ_sep_n, nucl_arr_sep_squ, 50, \"test.txt\", \"test_fromE.txt\", \"test_toE.txt\")\n",
    "print_control(nucl_arr_sep_squ, smat_squ_sep, 50, \"test_control.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confints_s(smat, precision, alpha_arr):\n",
    "    sum_A = colsum(smat_squ_sep, 'A')\n",
    "    sum_E = colsum(smat_squ_sep, 'E')\n",
    "    sum_G = colsum(smat_squ_sep, 'G')\n",
    "    \n",
    "    p_A2E = smat['A']['E']/sum_A\n",
    "    p_E2G = smat['E']['G']/sum_E\n",
    "    p_G2A = smat['G']['A']/sum_G\n",
    "    \n",
    "    p_A2G = smat['A']['G']/sum_A\n",
    "    p_E2A = smat['E']['A']/sum_E\n",
    "    p_G2E = smat['G']['E']/sum_G\n",
    "    \n",
    "    mean = (p_A2E * p_E2G * p_G2A)/(p_A2G * p_E2A * p_G2E)\n",
    "    \n",
    "    A2E = rand_arr_generate(precision, sum_A, p_A2E)\n",
    "    E2G = rand_arr_generate(precision, sum_E, p_E2G)\n",
    "    G2A = rand_arr_generate(precision, sum_G, p_G2A)\n",
    "    \n",
    "    A2G = rand_arr_generate(precision, sum_A, p_A2G)\n",
    "    E2A = rand_arr_generate(precision, sum_E, p_E2A)\n",
    "    G2E = rand_arr_generate(precision, sum_G, p_G2E)\n",
    "    \n",
    "    s_arr = []\n",
    "    \n",
    "    for i in range(precision):\n",
    "        s = (A2E[i] * E2G[i] * G2A[i])/(A2G[i] * E2A[i] * G2E[i])\n",
    "        s_arr.append(s)\n",
    "    \n",
    "    s_arr = sorted(s_arr)\n",
    "    \n",
    "    alpha_dict = dict()\n",
    "    for alpha in alpha_arr:\n",
    "        alpha_dict[alpha] = dict()\n",
    "        alpha_dict[alpha][\"min\"] = s_arr[int(precision*(alpha/2))]\n",
    "        alpha_dict[alpha][\"max\"] = s_arr[-int(precision*(alpha/2))]\n",
    "    \n",
    "    return mean, alpha_dict\n",
    "\n",
    "def info_string(mean, alpha_dict, alpha_arr):\n",
    "    out_s = []\n",
    "    out_s.append(mean)\n",
    "    for alpha in alpha_arr:\n",
    "        out_s.append(alpha_dict[alpha][\"min\"])\n",
    "        out_s.append(alpha_dict[alpha][\"max\"])\n",
    "    return \"\\t\".join(map(str, out_s))\n",
    "\n",
    "#p_A2E = smat_squ_sep['A']['E']/colsum(smat_squ_sep, 'A')\n",
    "#p_E2G = smat_squ_sep['E']['G']/colsum(smat_squ_sep, 'E')\n",
    "#p_A2G = smat_squ_sep['A']['G']/colsum(smat_squ_sep, 'A')\n",
    "#t1 = p_A2E*p_E2G/p_A2G\n",
    "#p_E2A = smat_squ_sep['E']['A']/colsum(smat_squ_sep, 'E')\n",
    "#p_G2E = smat_squ_sep['G']['E']/colsum(smat_squ_sep, 'G')\n",
    "#p_G2A = smat_squ_sep['G']['A']/colsum(smat_squ_sep, 'G')\n",
    "#t2 = p_E2A*p_G2E/p_G2A\n",
    "#print(t1/t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.396528879715465\t1.953490110468723\t2.8968766919813915\t1.8743425505551443\t2.999376499057548\t1.729082436209287\t3.2044693456760025\n",
      "1.146232535592408\t0.8528030869701642\t1.486025371211081\t0.8041925376472042\t1.5583736035731186\t0.7104157633824025\t1.7091871652409043\n",
      "7.0608605659339325\t5.089423460407033\t9.631816655952953\t4.762990691172163\t10.233212896524579\t4.178411020072537\t11.52434440412048\n"
     ]
    }
   ],
   "source": [
    "alpha_arr = [0.1, 0.05, 0.01]\n",
    "precision = 100000\n",
    "mean, alpha_dict = confints_s(smat_squ_sep, precision, alpha_arr)\n",
    "print(info_string(mean, alpha_dict, alpha_arr))\n",
    "\n",
    "mean, alpha_dict = confints_s(smat_squ_sep_syn, precision, alpha_arr)\n",
    "print(info_string(mean, alpha_dict, alpha_arr))\n",
    "\n",
    "mean, alpha_dict = confints_s(smat_squ_sep_nsyn, precision, alpha_arr)\n",
    "print(info_string(mean, alpha_dict, alpha_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
